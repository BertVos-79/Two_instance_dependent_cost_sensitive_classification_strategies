{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to normalize based on category bounds\n",
        "def normalize_category(value, bounds):\n",
        "    if value >= bounds[0]:\n",
        "        return 1.0\n",
        "    elif value <= bounds[-1]:\n",
        "        return 0.0\n",
        "    for i, bound in enumerate(bounds):\n",
        "        if value > bound:\n",
        "            return (len(bounds) - 1 - i) / (len(bounds) - 1)\n",
        "    return 0.0\n",
        "\n",
        "# Define category bounds for the Hosmer-Lemeshow and Link Test P-values, and Pseudo R-squared\n",
        "hosmer_lemeshow_bounds = [0.05, 0.01, 0.001, 0.0001, 0]\n",
        "link_test_bounds = [0.05, 0.01, 0.001, 0.0001, 0]\n",
        "pseudo_r_squared_bounds = [0.4, 0.3, 0.2, 0.1, 0]\n",
        "\n",
        "# Updated data dictionary with pseudo R-squared and link test p-value for each dataset\n",
        "data = {\n",
        "    'Dataset': ['MAGIC', 'ADULT', 'HABERMAN', 'TRANSFUSION'],\n",
        "    'Hosmer-Lemeshow P-value': [0.008555023891818947, 0.018650468284383104, 0.19664262393908305, 0.9180867891329492],\n",
        "    'BIC': [14075.734568215932, 20174.341739137355, 273.0410347735347, 588.3260145415767],\n",
        "    'Pseudo R-squared': [0.2918, 0.3036, 0.09929, 0.1385],\n",
        "    'Link Test P-value': [5.485e-160, 1.735e-19, 0.3449, 0.0001366]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Normalize the metrics\n",
        "df['Normalized Hosmer-Lemeshow'] = df['Hosmer-Lemeshow P-value'].apply(normalize_category, bounds=hosmer_lemeshow_bounds)\n",
        "df['Normalized Link Test'] = df['Link Test P-value'].apply(normalize_category, bounds=link_test_bounds)\n",
        "df['Normalized Pseudo R-squared'] = df['Pseudo R-squared'].apply(lambda x: normalize_category(x, pseudo_r_squared_bounds) if x > 0 else 0)\n",
        "df['Normalized BIC'] = 1 - (df['BIC'] - df['BIC'].min()) / (df['BIC'].max() - df['BIC'].min())\n",
        "\n",
        "# Weights as specified, ensuring correct order\n",
        "weights = np.array([1, 0.9, 0.4, 0.2])  # Adjusted to match columns correctly\n",
        "total_weight = weights.sum()\n",
        "\n",
        "# Calculate the overall Model Specification Score\n",
        "df['Overall Model Specification Score'] = (df[\n",
        "    ['Normalized Hosmer-Lemeshow', 'Normalized BIC', 'Normalized Pseudo R-squared', 'Normalized Link Test']\n",
        "].dot(weights) / total_weight) * 100\n",
        "\n",
        "df.sort_values(by='Overall Model Specification Score', ascending=False, inplace=True)\n",
        "\n",
        "# Define the categories based on the scores\n",
        "def categorize(score):\n",
        "    if score > 80:\n",
        "        return 'Very well specified'\n",
        "    elif 60 < score <= 80:\n",
        "        return 'Well Specified'\n",
        "    elif 40 < score <= 60:\n",
        "        return 'Average'\n",
        "    elif 15 < score <= 40:\n",
        "        return 'Misspecified'\n",
        "    else:\n",
        "        return 'Badly misspecified'\n",
        "\n",
        "# Apply categorization to the DataFrame\n",
        "df['Category'] = df['Overall Model Specification Score'].apply(categorize)\n",
        "\n",
        "# Explanation of model misspecification based on metrics\n",
        "explanations = {\n",
        "    'MAGIC': [\n",
        "        'Low Hosmer-Lemeshow P-value indicates poor fit, suggesting possible model misspecification.',\n",
        "        'Highly significant Link Test P-value indicates that the model might be omitting important predictors or using an incorrect functional form.',\n",
        "        'Pseudo R-squared value indicates moderate explanatory power but still under the acceptable threshold for a good fit.',\n",
        "        'Relatively high BIC score indicates potential overfitting or excessive complexity.'\n",
        "    ],\n",
        "    'ADULT': [\n",
        "        'Low Hosmer-Lemeshow P-value suggests a poor fit, indicative of model misspecification.',\n",
        "        'Significant Link Test P-value implies potential errors in model form or omitted variables.',\n",
        "        'Pseudo R-squared indicates moderate explanatory power, which is generally acceptable but not ideal.',\n",
        "        'High BIC score suggests significant overfitting or unnecessary complexity, indicating poor model specification.'\n",
        "    ],\n",
        "    'HABERMAN': [\n",
        "        'Higher Hosmer-Lemeshow P-value indicates a better fit compared to other datasets, suggesting lesser misspecification.',\n",
        "        'Non-significant Link Test P-value implies that the model form may be appropriate for the data.',\n",
        "        'Low Pseudo R-squared value suggests limited explanatory power, indicating potential underfitting.',\n",
        "        'Low BIC score suggests a more efficient model in terms of simplicity and fit.'\n",
        "    ],\n",
        "    'TRANSFUSION': [\n",
        "        'High Hosmer-Lemeshow P-value indicates a good fit, suggesting minimal model misspecification.',\n",
        "        'Significant Link Test P-value indicates potential errors in model specification.',\n",
        "        'Pseudo R-squared is relatively low, indicating that the model explains only a small portion of the variance in the outcome.',\n",
        "        'Moderate BIC score indicates a reasonable balance between model complexity and fit.'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Print DataFrame for overview\n",
        "print(df[['Dataset', 'Overall Model Specification Score', 'Category']])\n",
        "\n",
        "# Prepare a DataFrame to hold categorizations, Model Specification Scores, and explanations\n",
        "category_explanations = pd.DataFrame(\n",
        "    columns=['Model Specification Score', 'Badly misspecified', 'Misspecified', 'Average',\n",
        "             'Well Specified', 'Very well specified'],\n",
        "    index=df['Dataset']\n",
        ")\n",
        "\n",
        "# Insert the 'Model Specification Score' from df to category_explanations\n",
        "category_explanations['Model Specification Score'] = df['Overall Model Specification Score'].values\n",
        "\n",
        "# Format the 'Model Specification Score' to display only two decimal places\n",
        "category_explanations['Model Specification Score'] = category_explanations['Model Specification Score'].map(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "# Map each dataset to its explanation\n",
        "for dataset in df['Dataset']:\n",
        "    category = df[df['Dataset'] == dataset]['Category'].values[0]\n",
        "    explanations_list = explanations[dataset]  # Corrected to use the dictionary\n",
        "    category_explanations.at[dataset, category] = \"\\n\".join(explanations_list)\n",
        "\n",
        "# Save the DataFrame to a CSV\n",
        "output_path = '/content/dataset_categorization.csv'\n",
        "category_explanations.to_csv(output_path)\n",
        "\n",
        "# Print the path to the output CSV file\n",
        "print(output_path)\n"
      ],
      "metadata": {
        "id": "t05l6o-GDeZQ",
        "outputId": "423ca7b2-1094-4241-917b-3405ac270e48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Dataset  Overall Model Specification Score             Category\n",
            "2     HABERMAN                          84.000000  Very well specified\n",
            "3  TRANSFUSION                          81.429672  Very well specified\n",
            "1        ADULT                          42.000000              Average\n",
            "0        MAGIC                          39.031935         Misspecified\n",
            "/content/dataset_categorization.csv\n"
          ]
        }
      ]
    }
  ]
}