{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Average datasets"
      ],
      "metadata": {
        "id": "WZFViPmMoZry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calibrated actual datasets"
      ],
      "metadata": {
        "id": "wlv1pgYdsoEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to normalize based on category bounds\n",
        "def normalize_category(value, bounds):\n",
        "    if value >= bounds[0]:\n",
        "        return 1.0\n",
        "    elif value <= bounds[-1]:\n",
        "        return 0.0\n",
        "    for i, bound in enumerate(bounds):\n",
        "        if value > bound:\n",
        "            return (len(bounds) - 1 - i) / (len(bounds) - 1)\n",
        "    return 0.0\n",
        "\n",
        "# Define category bounds for the Hosmer-Lemeshow and Link Test P-values, and Pseudo R-squared\n",
        "hosmer_lemeshow_bounds = [0.05, 0.01, 0.001, 0.0001, 0]\n",
        "link_test_bounds = [0.05, 0.01, 0.001, 0.0001, 0]\n",
        "pseudo_r_squared_bounds = [0.4, 0.3, 0.2, 0.1, 0]\n",
        "\n",
        "# Updated data dictionary with pseudo R-squared and link test p-value for each dataset\n",
        "data = {\n",
        "    'Dataset': ['Credit Card Fraud 2', 'Vehicle Insurance Fraud', 'Credit Card Fraud 1',\n",
        "                'E-commerce Customer Churn Prediction', 'Bank Customer Churn Prediction',\n",
        "                'Telecom Customer Churn Prediction'],\n",
        "    'Hosmer-Lemeshow P-value': [0.0, 0.7971637749060193, 0.0, 2.9949334678258666e-05,\n",
        "                                0.0023718870447108076, 0.026343609988660255],\n",
        "    'BIC': [12969.707112923728, 4893.057, 21340.899, 2358.939, 7009.424, 4157.111],\n",
        "    'Pseudo R-squared': [0.7159, 0.1565, 0.5552, 0.6282, 0.1508,  0.4102],\n",
        "    'Link Test P-value': [1.000, 1.219e-24, 0.0, 5.485e-160, 7.398e-64, 1.502e-113]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Normalize the metrics\n",
        "df['Normalized Hosmer-Lemeshow'] = df['Hosmer-Lemeshow P-value'].apply(normalize_category, bounds=hosmer_lemeshow_bounds)\n",
        "df['Normalized Link Test'] = df['Link Test P-value'].apply(normalize_category, bounds=link_test_bounds)\n",
        "df['Normalized Pseudo R-squared'] = df['Pseudo R-squared'].apply(lambda x: normalize_category(x, pseudo_r_squared_bounds) if x > 0 else 0)\n",
        "df['Normalized BIC'] = 1 - (df['BIC'] - df['BIC'].min()) / (df['BIC'].max() - df['BIC'].min())\n",
        "\n",
        "# Weights as specified, ensuring correct order\n",
        "weights = np.array([1, 0.9, 0.4, 0.2])  # Adjusted to match columns correctly\n",
        "total_weight = weights.sum()\n",
        "\n",
        "# Calculate the overall Model Specification Score\n",
        "df['Overall Model Specification Score'] = (df[\n",
        "    ['Normalized Hosmer-Lemeshow', 'Normalized BIC', 'Normalized Pseudo R-squared', 'Normalized Link Test']\n",
        "].dot(weights) / total_weight) * 100\n",
        "\n",
        "df.sort_values(by='Overall Model Specification Score', ascending=False, inplace=True)\n",
        "\n",
        "# Define the categories based on the scores\n",
        "def categorize(score):\n",
        "    if score > 80:\n",
        "        return 'Very well specified'\n",
        "    elif 60 < score <= 80:\n",
        "        return 'Well Specified'\n",
        "    elif 40 < score <= 60:\n",
        "        return 'Average'\n",
        "    elif 20 < score <= 40:\n",
        "        return 'Misspecified'\n",
        "    else:\n",
        "        return 'Badly misspecified'\n",
        "\n",
        "# Apply categorization to the DataFrame\n",
        "df['Category'] = df['Overall Model Specification Score'].apply(categorize)\n",
        "print(df[['Dataset', 'Overall Model Specification Score', 'Category']])\n",
        "\n",
        "# Print DataFrame for overview\n",
        "print(df)\n",
        "# Save the DataFrame to a CSV\n",
        "output_path_0 = '/content/short_overview_datasets_ranking.csv'\n",
        "df.to_csv(output_path_0)\n",
        "\n",
        "# Print the path to the output CSV file\n",
        "print(output_path_0)\n",
        "\n",
        "explanations = {\n",
        "    'Credit Card Fraud 2': [\n",
        "        'The Hosmer-Lemeshow test value of 0.0 indicates extremely poor model calibration.',\n",
        "        'A BIC value of 12,969.71 suggests significant inefficiency and likely model overfitting.',\n",
        "        'A relatively high value of 0.7159 suggests that the model has strong explanatory power despite other indicators of poor specification.',\n",
        "        'The Link Test p-value of 1.000 implies a correctly specified model under this metric alone, contradicting other indicators.'\n",
        "    ],\n",
        "    'Vehicle Insurance Fraud': [\n",
        "        'A value of 0.797 suggests good model fit and calibration across different deciles.',\n",
        "        'The BIC value of 4,893.057 indicates a balance between model fit and complexity.',\n",
        "        'A low value of 0.1565 suggests the model explains only a small variance of the dependent variable.',\n",
        "        'The extremely low Link Test p-value (1.219e-24) indicates potential misspecification issues.'\n",
        "    ],\n",
        "    'Credit Card Fraud 1': [\n",
        "        'A p-value of 0.0 signals a poor fit, showing significant discrepancies between expected and observed values.',\n",
        "        'A very high BIC of 21,340.899 suggests considerable model inefficiency and probable overfitting.',\n",
        "        'The model\"s Pseudo R-squared of 0.5552 indicates moderate explanatory power.',\n",
        "        'A Link Test p-value of 0.0 indicates the model\"s functional form may be misspecified.'\n",
        "    ],\n",
        "    'E-commerce Customer Churn Prediction': [\n",
        "        'A very low value (2.994e-05) indicates a poor fit.',\n",
        "        'A relatively low BIC of 2,358.939 suggests a reasonable balance between simplicity and fit.',\n",
        "        'The Pseudo R-squared value of 0.6282 suggests a relatively good explanation of variance by the model.',\n",
        "        'The extremely low p-value (5.485e-160) indicates potential issues with the model\"s functional form.'\n",
        "    ],\n",
        "    'Bank Customer Churn Prediction': [\n",
        "        'A p-value of 0.0024 suggests discrepancies in model calibration.',\n",
        "        'The BIC value of 7,009.424 indicates potential for improvement in model fit or complexity.',\n",
        "        'A Pseudo R-squared of 0.1508 shows limited model effectiveness in explaining the variance.',\n",
        "        'The p-value of 7.398e-64 points to potential misspecification.'\n",
        "    ],\n",
        "    'Telecom Customer Churn Prediction': [\n",
        "        'A value of 0.0263 suggests poor fit with significant calibration issues.',\n",
        "        'A BIC value of 4,157.111 points to a reasonable fit with some room for improvement.',\n",
        "        'A Pseudo R-squared of 0.4102 indicates adequate explanatory power.',\n",
        "        'The low Link Test p-value (1.502e-113) suggests potential issues with the model\"s functional form.'\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Prepare a DataFrame to hold categorizations, Model Specification Scores, and explanations\n",
        "category_explanations = pd.DataFrame(\n",
        "    columns=['Model Specification Score', 'Badly misspecified', 'Misspecified', 'Average',\n",
        "             'Well Specified', 'Very well specified'],\n",
        "    index=df['Dataset']\n",
        ")\n",
        "\n",
        "# Insert the 'Model Specification Score' from df to category_explanations\n",
        "category_explanations['Model Specification Score'] = df['Overall Model Specification Score'].values\n",
        "\n",
        "# Format the 'Model Specification Score' to display only two decimal places\n",
        "category_explanations['Model Specification Score'] = category_explanations['Model Specification Score'].map(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "# Map each dataset to its explanation\n",
        "for dataset in df['Dataset']:\n",
        "    category = df[df['Dataset'] == dataset]['Category'].values[0]\n",
        "    explanations_list = explanations[dataset]  # Corrected to use the dictionary\n",
        "    category_explanations.at[dataset, category] = \"\\n\".join(explanations_list)\n",
        "\n",
        "# Save the DataFrame to a CSV\n",
        "output_path = '/content/dataset_categorization.csv'\n",
        "category_explanations.to_csv(output_path)\n",
        "\n",
        "# Print the path to the output CSV file\n",
        "print(output_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epankhQRLsbF",
        "outputId": "ef44559e-f780-4915-d766-1ab6e20c1b98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                Dataset  Overall Model Specification Score  \\\n",
            "5     Telecom Customer Churn Prediction                          78.589699   \n",
            "1               Vehicle Insurance Fraud                          75.193950   \n",
            "3  E-commerce Customer Churn Prediction                          52.000000   \n",
            "4        Bank Customer Churn Prediction                          51.180181   \n",
            "0                   Credit Card Fraud 2                          39.876280   \n",
            "2                   Credit Card Fraud 1                          16.000000   \n",
            "\n",
            "             Category  \n",
            "5      Well Specified  \n",
            "1      Well Specified  \n",
            "3             Average  \n",
            "4             Average  \n",
            "0        Misspecified  \n",
            "2  Badly misspecified  \n",
            "                                Dataset  Hosmer-Lemeshow P-value  \\\n",
            "5     Telecom Customer Churn Prediction                 0.026344   \n",
            "1               Vehicle Insurance Fraud                 0.797164   \n",
            "3  E-commerce Customer Churn Prediction                 0.000030   \n",
            "4        Bank Customer Churn Prediction                 0.002372   \n",
            "0                   Credit Card Fraud 2                 0.000000   \n",
            "2                   Credit Card Fraud 1                 0.000000   \n",
            "\n",
            "            BIC  Pseudo R-squared  Link Test P-value  \\\n",
            "5   4157.111000            0.4102      1.502000e-113   \n",
            "1   4893.057000            0.1565       1.219000e-24   \n",
            "3   2358.939000            0.6282      5.485000e-160   \n",
            "4   7009.424000            0.1508       7.398000e-64   \n",
            "0  12969.707113            0.7159       1.000000e+00   \n",
            "2  21340.899000            0.5552       0.000000e+00   \n",
            "\n",
            "   Normalized Hosmer-Lemeshow  Normalized Link Test  \\\n",
            "5                        0.75                   0.0   \n",
            "1                        1.00                   0.0   \n",
            "3                        0.00                   0.0   \n",
            "4                        0.50                   0.0   \n",
            "0                        0.00                   1.0   \n",
            "2                        0.00                   0.0   \n",
            "\n",
            "   Normalized Pseudo R-squared  Normalized BIC  \\\n",
            "5                         1.00        0.905269   \n",
            "1                         0.25        0.866499   \n",
            "3                         1.00        1.000000   \n",
            "4                         0.25        0.755005   \n",
            "0                         1.00        0.441008   \n",
            "2                         1.00        0.000000   \n",
            "\n",
            "   Overall Model Specification Score            Category  \n",
            "5                          78.589699      Well Specified  \n",
            "1                          75.193950      Well Specified  \n",
            "3                          52.000000             Average  \n",
            "4                          51.180181             Average  \n",
            "0                          39.876280        Misspecified  \n",
            "2                          16.000000  Badly misspecified  \n",
            "/content/short_overview_datasets_ranking.csv\n",
            "/content/dataset_categorization.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Actual datasets"
      ],
      "metadata": {
        "id": "YPt9CCoFoW9k"
      }
    }
  ]
}